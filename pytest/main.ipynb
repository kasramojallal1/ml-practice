{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytest\n",
      "  Downloading pytest-8.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/miniconda3/envs/ml-practice/lib/python3.8/site-packages (from pytest) (1.2.2)\n",
      "Collecting iniconfig (from pytest)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/ml-practice/lib/python3.8/site-packages (from pytest) (24.2)\n",
      "Collecting pluggy<2,>=1.5 (from pytest)\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tomli>=1 (from pytest)\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading pytest-8.3.4-py3-none-any.whl (343 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: tomli, pluggy, iniconfig, pytest\n",
      "Successfully installed iniconfig-2.0.0 pluggy-1.5.0 pytest-8.3.4 tomli-2.2.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytest 8.3.4\n"
     ]
    }
   ],
   "source": [
    "! pytest --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.20, pytest-8.3.4, pluggy-1.5.0\n",
      "rootdir: /Users/kasra/Codes/ml-practice/pytest\n",
      "plugins: anyio-4.5.2, typeguard-2.13.3\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_example.py \u001b[31mF\u001b[0m\u001b[31m                                                        [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________________________________ test_addition _________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_addition\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[94m2\u001b[39;49;00m + \u001b[94m3\u001b[39;49;00m == \u001b[94m5\u001b[39;49;00m  \u001b[90m# Passes\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[94m5\u001b[39;49;00m - \u001b[94m1\u001b[39;49;00m == \u001b[94m3\u001b[39;49;00m  \u001b[90m# Fails (Incorrect)\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert (5 - 1) == 3\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_example.py\u001b[0m:3: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_example.py::\u001b[1mtest_addition\u001b[0m - assert (5 - 1) == 3\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.10s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest test_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.20, pytest-8.3.4, pluggy-1.5.0 -- /opt/miniconda3/envs/ml-practice/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/kasra/Codes/ml-practice/pytest\n",
      "plugins: anyio-4.5.2, typeguard-2.13.3\n",
      "collected 1 item                                                               \u001b[0m\n",
      "\n",
      "test_example2.py::test_data \u001b[32mPASSED\u001b[0m\u001b[32m                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v test_example2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.20, pytest-8.3.4, pluggy-1.5.0 -- /opt/miniconda3/envs/ml-practice/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/kasra/Codes/ml-practice/pytest\n",
      "plugins: anyio-4.5.2, typeguard-2.13.3\n",
      "collected 0 items / 1 error                                                    \u001b[0m\u001b[1m\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m______________________ ERROR collecting test_example3.py _______________________\u001b[0m\n",
      "\u001b[1m\u001b[31mtest_example3.py\u001b[0m:5: in <module>\n",
      "    \u001b[0m\u001b[94mwith\u001b[39;49;00m \u001b[96mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.pkl\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m file:\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   FileNotFoundError: [Errno 2] No such file or directory: 'model.pkl'\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m test_example3.py - FileNotFoundError: [Errno 2] No such file or directory: 'model.pkl'\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 6.16s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest -v test_example3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ML_model_creation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.20, pytest-8.3.4, pluggy-1.5.0 -- /opt/miniconda3/envs/ml-practice/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /Users/kasra/Codes/ml-practice/pytest\n",
      "plugins: anyio-4.5.2, typeguard-2.13.3\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "test_ML_model.py::test_model_prediction \u001b[31mFAILED\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ test_model_prediction _____________________________\u001b[0m\n",
      "\n",
      "capsys = <_pytest.capture.CaptureFixture object at 0x12ffd6580>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_model_prediction\u001b[39;49;00m(capsys):\u001b[90m\u001b[39;49;00m\n",
      "        sample_input = [\u001b[94m5.1\u001b[39;49;00m, \u001b[94m3.5\u001b[39;49;00m, \u001b[94m1.4\u001b[39;49;00m, \u001b[94m0.2\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "        prediction = predict(sample_input)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(prediction)  \u001b[90m# Captured by capsys\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mPrediction Output:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, prediction)\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mType of Prediction:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[96mtype\u001b[39;49;00m(prediction))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        captured = capsys.readouterr()  \u001b[90m# Get captured output\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mPrediction\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m captured.err  \u001b[90m# Check no errors\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[96misinstance\u001b[39;49;00m(prediction[\u001b[94m0\u001b[39;49;00m], \u001b[96mint\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       assert False\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where False = isinstance(0, int)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_ML_model.py\u001b[0m:21: AssertionError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_ML_model.py::\u001b[1mtest_model_prediction\u001b[0m - assert False\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.96s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pytest test_ML_model.py -v -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
